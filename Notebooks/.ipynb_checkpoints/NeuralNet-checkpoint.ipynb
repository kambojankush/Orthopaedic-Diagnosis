{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./vertebral_column_data/column_3C.dat', delimiter = ' ', header = None)\n",
    "X = dataset.iloc[:,0:-1].values\n",
    "Y = dataset.iloc[:,-1].values\n",
    "\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "Y = np.reshape(Y,(310,1))\n",
    "onehotencoder = OneHotEncoder(categorical_features=[0])\n",
    "Y = onehotencoder.fit_transform(Y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2,random_state = 0)\n",
    " \n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    " \n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(units=5, input_dim = 6, kernel_initializer='uniform', activation='relu'))\n",
    " \n",
    "classifier.add(Dense(units=4, kernel_initializer='uniform', activation='relu'))\n",
    " \n",
    "classifier.add(Dense(units=3,  kernel_initializer='uniform', activation='softmax'))\n",
    " \n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy',metrics = ['accuracy'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "248/248 [==============================] - 0s 951us/step - loss: 1.0961 - acc: 0.4718\n",
      "Epoch 2/100\n",
      "248/248 [==============================] - 0s 118us/step - loss: 1.0910 - acc: 0.4839\n",
      "Epoch 3/100\n",
      "248/248 [==============================] - 0s 144us/step - loss: 1.0857 - acc: 0.4839\n",
      "Epoch 4/100\n",
      "248/248 [==============================] - 0s 165us/step - loss: 1.0784 - acc: 0.4839\n",
      "Epoch 5/100\n",
      "248/248 [==============================] - 0s 128us/step - loss: 1.0664 - acc: 0.4839\n",
      "Epoch 6/100\n",
      "248/248 [==============================] - 0s 117us/step - loss: 1.0460 - acc: 0.4839\n",
      "Epoch 7/100\n",
      "248/248 [==============================] - 0s 127us/step - loss: 1.0136 - acc: 0.5081\n",
      "Epoch 8/100\n",
      "248/248 [==============================] - 0s 128us/step - loss: 0.9663 - acc: 0.6210\n",
      "Epoch 9/100\n",
      "248/248 [==============================] - 0s 126us/step - loss: 0.9105 - acc: 0.6774\n",
      "Epoch 10/100\n",
      "248/248 [==============================] - 0s 150us/step - loss: 0.8507 - acc: 0.7016\n",
      "Epoch 11/100\n",
      "248/248 [==============================] - 0s 129us/step - loss: 0.7976 - acc: 0.7177\n",
      "Epoch 12/100\n",
      "248/248 [==============================] - 0s 117us/step - loss: 0.7513 - acc: 0.7097\n",
      "Epoch 13/100\n",
      "248/248 [==============================] - 0s 137us/step - loss: 0.7165 - acc: 0.6895\n",
      "Epoch 14/100\n",
      "248/248 [==============================] - 0s 121us/step - loss: 0.6892 - acc: 0.6935\n",
      "Epoch 15/100\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.5978 - acc: 0.700 - 0s 135us/step - loss: 0.6687 - acc: 0.6895\n",
      "Epoch 16/100\n",
      "248/248 [==============================] - 0s 130us/step - loss: 0.6530 - acc: 0.6935\n",
      "Epoch 17/100\n",
      "248/248 [==============================] - 0s 121us/step - loss: 0.6395 - acc: 0.6976\n",
      "Epoch 18/100\n",
      "248/248 [==============================] - 0s 131us/step - loss: 0.6279 - acc: 0.7016\n",
      "Epoch 19/100\n",
      "248/248 [==============================] - 0s 118us/step - loss: 0.6186 - acc: 0.7016\n",
      "Epoch 20/100\n",
      "248/248 [==============================] - 0s 127us/step - loss: 0.6091 - acc: 0.7056\n",
      "Epoch 21/100\n",
      "248/248 [==============================] - 0s 131us/step - loss: 0.6008 - acc: 0.7056\n",
      "Epoch 22/100\n",
      "248/248 [==============================] - 0s 159us/step - loss: 0.5931 - acc: 0.7097\n",
      "Epoch 23/100\n",
      "248/248 [==============================] - 0s 123us/step - loss: 0.5855 - acc: 0.7097\n",
      "Epoch 24/100\n",
      "248/248 [==============================] - 0s 120us/step - loss: 0.5770 - acc: 0.7137\n",
      "Epoch 25/100\n",
      "248/248 [==============================] - 0s 116us/step - loss: 0.5689 - acc: 0.7218\n",
      "Epoch 26/100\n",
      "248/248 [==============================] - 0s 154us/step - loss: 0.5601 - acc: 0.7218\n",
      "Epoch 27/100\n",
      "248/248 [==============================] - 0s 116us/step - loss: 0.5505 - acc: 0.7258\n",
      "Epoch 28/100\n",
      "248/248 [==============================] - 0s 132us/step - loss: 0.5399 - acc: 0.7258\n",
      "Epoch 29/100\n",
      "248/248 [==============================] - 0s 127us/step - loss: 0.5308 - acc: 0.7339\n",
      "Epoch 30/100\n",
      "248/248 [==============================] - 0s 121us/step - loss: 0.5212 - acc: 0.7419\n",
      "Epoch 31/100\n",
      "248/248 [==============================] - 0s 122us/step - loss: 0.5118 - acc: 0.7379\n",
      "Epoch 32/100\n",
      "248/248 [==============================] - 0s 130us/step - loss: 0.5030 - acc: 0.7419\n",
      "Epoch 33/100\n",
      "248/248 [==============================] - 0s 115us/step - loss: 0.4946 - acc: 0.7460\n",
      "Epoch 34/100\n",
      "248/248 [==============================] - 0s 122us/step - loss: 0.4870 - acc: 0.7460\n",
      "Epoch 35/100\n",
      "248/248 [==============================] - 0s 115us/step - loss: 0.4800 - acc: 0.7460\n",
      "Epoch 36/100\n",
      "248/248 [==============================] - 0s 132us/step - loss: 0.4729 - acc: 0.7581\n",
      "Epoch 37/100\n",
      "248/248 [==============================] - 0s 135us/step - loss: 0.4662 - acc: 0.7621\n",
      "Epoch 38/100\n",
      "248/248 [==============================] - 0s 138us/step - loss: 0.4600 - acc: 0.7661\n",
      "Epoch 39/100\n",
      "248/248 [==============================] - 0s 119us/step - loss: 0.4542 - acc: 0.7702\n",
      "Epoch 40/100\n",
      "248/248 [==============================] - 0s 136us/step - loss: 0.4490 - acc: 0.7742\n",
      "Epoch 41/100\n",
      "248/248 [==============================] - 0s 112us/step - loss: 0.4439 - acc: 0.7782\n",
      "Epoch 42/100\n",
      "248/248 [==============================] - 0s 128us/step - loss: 0.4392 - acc: 0.7823\n",
      "Epoch 43/100\n",
      "248/248 [==============================] - 0s 120us/step - loss: 0.4357 - acc: 0.7823\n",
      "Epoch 44/100\n",
      "248/248 [==============================] - 0s 116us/step - loss: 0.4318 - acc: 0.7823\n",
      "Epoch 45/100\n",
      "248/248 [==============================] - 0s 122us/step - loss: 0.4286 - acc: 0.7823\n",
      "Epoch 46/100\n",
      "248/248 [==============================] - 0s 112us/step - loss: 0.4253 - acc: 0.7823\n",
      "Epoch 47/100\n",
      "248/248 [==============================] - 0s 127us/step - loss: 0.4231 - acc: 0.7863\n",
      "Epoch 48/100\n",
      "248/248 [==============================] - 0s 118us/step - loss: 0.4203 - acc: 0.7863\n",
      "Epoch 49/100\n",
      "248/248 [==============================] - 0s 116us/step - loss: 0.4181 - acc: 0.7863\n",
      "Epoch 50/100\n",
      "248/248 [==============================] - 0s 128us/step - loss: 0.4151 - acc: 0.7863\n",
      "Epoch 51/100\n",
      "248/248 [==============================] - 0s 124us/step - loss: 0.4127 - acc: 0.7863\n",
      "Epoch 52/100\n",
      "248/248 [==============================] - 0s 103us/step - loss: 0.4111 - acc: 0.7863\n",
      "Epoch 53/100\n",
      "248/248 [==============================] - 0s 113us/step - loss: 0.4091 - acc: 0.7863\n",
      "Epoch 54/100\n",
      "248/248 [==============================] - 0s 127us/step - loss: 0.4074 - acc: 0.7863\n",
      "Epoch 55/100\n",
      "248/248 [==============================] - 0s 95us/step - loss: 0.4051 - acc: 0.7863\n",
      "Epoch 56/100\n",
      "248/248 [==============================] - 0s 141us/step - loss: 0.4030 - acc: 0.7863\n",
      "Epoch 57/100\n",
      "248/248 [==============================] - 0s 116us/step - loss: 0.4008 - acc: 0.7863\n",
      "Epoch 58/100\n",
      "248/248 [==============================] - 0s 109us/step - loss: 0.4000 - acc: 0.7863\n",
      "Epoch 59/100\n",
      "248/248 [==============================] - 0s 130us/step - loss: 0.3976 - acc: 0.7903\n",
      "Epoch 60/100\n",
      "248/248 [==============================] - 0s 116us/step - loss: 0.3953 - acc: 0.7863\n",
      "Epoch 61/100\n",
      "248/248 [==============================] - 0s 119us/step - loss: 0.3928 - acc: 0.8024\n",
      "Epoch 62/100\n",
      "248/248 [==============================] - 0s 116us/step - loss: 0.3911 - acc: 0.8065\n",
      "Epoch 63/100\n",
      "248/248 [==============================] - 0s 126us/step - loss: 0.3894 - acc: 0.8065\n",
      "Epoch 64/100\n",
      "248/248 [==============================] - 0s 109us/step - loss: 0.3874 - acc: 0.8024\n",
      "Epoch 65/100\n",
      "248/248 [==============================] - 0s 114us/step - loss: 0.3860 - acc: 0.8065\n",
      "Epoch 66/100\n",
      "248/248 [==============================] - 0s 110us/step - loss: 0.3839 - acc: 0.8145\n",
      "Epoch 67/100\n",
      "248/248 [==============================] - 0s 110us/step - loss: 0.3830 - acc: 0.8185\n",
      "Epoch 68/100\n",
      "248/248 [==============================] - 0s 109us/step - loss: 0.3806 - acc: 0.8185\n",
      "Epoch 69/100\n",
      "248/248 [==============================] - 0s 115us/step - loss: 0.3801 - acc: 0.8145\n",
      "Epoch 70/100\n",
      "248/248 [==============================] - 0s 110us/step - loss: 0.3772 - acc: 0.8226\n",
      "Epoch 71/100\n",
      "248/248 [==============================] - 0s 112us/step - loss: 0.3752 - acc: 0.8185\n",
      "Epoch 72/100\n",
      "248/248 [==============================] - 0s 117us/step - loss: 0.3742 - acc: 0.8226\n",
      "Epoch 73/100\n",
      "248/248 [==============================] - 0s 127us/step - loss: 0.3710 - acc: 0.8266\n",
      "Epoch 74/100\n",
      "248/248 [==============================] - 0s 119us/step - loss: 0.3699 - acc: 0.8226\n",
      "Epoch 75/100\n",
      "248/248 [==============================] - 0s 109us/step - loss: 0.3677 - acc: 0.8266\n",
      "Epoch 76/100\n",
      "248/248 [==============================] - 0s 114us/step - loss: 0.3668 - acc: 0.8266\n",
      "Epoch 77/100\n",
      "248/248 [==============================] - 0s 118us/step - loss: 0.3641 - acc: 0.8266\n",
      "Epoch 78/100\n",
      "248/248 [==============================] - 0s 113us/step - loss: 0.3625 - acc: 0.8266\n",
      "Epoch 79/100\n",
      "248/248 [==============================] - 0s 107us/step - loss: 0.3595 - acc: 0.8226\n",
      "Epoch 80/100\n",
      "248/248 [==============================] - 0s 117us/step - loss: 0.3574 - acc: 0.8226\n",
      "Epoch 81/100\n",
      "248/248 [==============================] - 0s 112us/step - loss: 0.3560 - acc: 0.8266\n",
      "Epoch 82/100\n",
      "248/248 [==============================] - 0s 119us/step - loss: 0.3558 - acc: 0.8387\n",
      "Epoch 83/100\n",
      "248/248 [==============================] - 0s 114us/step - loss: 0.3511 - acc: 0.8306\n",
      "Epoch 84/100\n",
      "248/248 [==============================] - 0s 112us/step - loss: 0.3498 - acc: 0.8266\n",
      "Epoch 85/100\n",
      "248/248 [==============================] - 0s 119us/step - loss: 0.3480 - acc: 0.8306\n",
      "Epoch 86/100\n",
      "248/248 [==============================] - 0s 110us/step - loss: 0.3459 - acc: 0.8347\n",
      "Epoch 87/100\n",
      "248/248 [==============================] - 0s 110us/step - loss: 0.3430 - acc: 0.8347\n",
      "Epoch 88/100\n",
      "248/248 [==============================] - 0s 106us/step - loss: 0.3413 - acc: 0.8387\n",
      "Epoch 89/100\n",
      "248/248 [==============================] - 0s 122us/step - loss: 0.3385 - acc: 0.8387\n",
      "Epoch 90/100\n",
      "248/248 [==============================] - 0s 102us/step - loss: 0.3374 - acc: 0.8427\n",
      "Epoch 91/100\n",
      "248/248 [==============================] - 0s 120us/step - loss: 0.3342 - acc: 0.8387\n",
      "Epoch 92/100\n",
      "248/248 [==============================] - 0s 107us/step - loss: 0.3338 - acc: 0.8468\n",
      "Epoch 93/100\n",
      "248/248 [==============================] - 0s 121us/step - loss: 0.3308 - acc: 0.8508\n",
      "Epoch 94/100\n",
      "248/248 [==============================] - 0s 121us/step - loss: 0.3285 - acc: 0.8589\n",
      "Epoch 95/100\n",
      "248/248 [==============================] - 0s 109us/step - loss: 0.3272 - acc: 0.8710\n",
      "Epoch 96/100\n",
      "248/248 [==============================] - 0s 109us/step - loss: 0.3245 - acc: 0.8831\n",
      "Epoch 97/100\n",
      "248/248 [==============================] - 0s 109us/step - loss: 0.3230 - acc: 0.8710\n",
      "Epoch 98/100\n",
      "248/248 [==============================] - 0s 120us/step - loss: 0.3209 - acc: 0.8871\n",
      "Epoch 99/100\n",
      "248/248 [==============================] - 0s 98us/step - loss: 0.3194 - acc: 0.8790\n",
      "Epoch 100/100\n",
      "248/248 [==============================] - 0s 114us/step - loss: 0.3171 - acc: 0.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc05b9ded68>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,Y_train,epochs = 100, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "Y_pred = classifier.predict(X_test)\n",
    "Y_pred = (Y_pred>0.5).astype(float)\n",
    "print(Y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
